# Towards Multimodal Inductive Learning: Adaptively Embedding MMKG via Prototypes

## Overview
<p align="center">
  <img src="model.jpg" alt="IndMMKG" width="1000">
</p>
The overall architecture of the IndMKG model.

## üéÜRequirments
- Python==3.10
- numpy==1.26.3
- torch==2.1.2
- tqdm==4.66.5
- wheel==0.44.0

## Implementation Details
Our experiments were conducted on NVIDIA RTX L20 GPUs with 48GB of RAM. We configured the training process for 20 epochs, using a batch size of 64, with modality embedding dimensions set to 128 and the number of negative samples set to 512. We employed the Adam optimizer for parameter learning, setting its learning rate to 5 √ó 10‚àí4. 


## ü§ùResult 
<p align="center">
  <img src="model.jpg" alt="IndMMKG" width="1000">
</p>

## Citation
```python
@inproceedings{
  title={},
  author={},
  booktitle={},
  pages={},
  year={}

}
```
